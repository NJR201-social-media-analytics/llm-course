{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b59f95",
   "metadata": {},
   "source": [
    "# LangChain Pipeline æ ¸å¿ƒæŠ€è¡“\n",
    "\n",
    "æ­¡è¿ä¾†åˆ° LangChain Pipeline æ ¸å¿ƒæŠ€è¡“èª²ç¨‹ï¼æœ¬èª²ç¨‹å°‡æ·±å…¥ä»‹ç´¹ LangChain ç®¡é“è¨­è¨ˆçš„é—œéµæŠ€è¡“ã€‚\n",
    "\n",
    "## ğŸ¯ èª²ç¨‹ç›®æ¨™\n",
    "\n",
    "åœ¨ç¬¬ 03 èª²ä¸­ï¼Œæˆ‘å€‘å­¸æœƒäº† PromptTemplate çš„é€²éšæ‡‰ç”¨ã€‚ç¾åœ¨æˆ‘å€‘è¦å­¸ç¿’å¦‚ä½•å°‡é€™äº›çµ„ä»¶çµ„åˆæˆå¼·å¤§çš„è™•ç†ç®¡é“ã€‚\n",
    "\n",
    "### ğŸ“‹ æœ¬èª²ç¨‹æ¶µè“‹çš„é—œéµæŠ€è¡“\n",
    "\n",
    "1. **LangChain ç®¡é“ï¼ˆPipelineï¼‰** - ä½¿ç”¨ `|` é‹ç®—å­çµ„åˆçµ„ä»¶\n",
    "2. **çµæ§‹åŒ–è¼¸å‡ºèˆ‡ JSON è§£æ** - è®“ LLM è¿”å›çµæ§‹åŒ–æ•¸æ“š\n",
    "3. **éŒ¯èª¤è™•ç†èˆ‡å®¹éŒ¯æ©Ÿåˆ¶** - ç”Ÿç”¢ç’°å¢ƒçš„ç©©å®šæ€§ä¿è­‰\n",
    "4. **æ‰¹é‡è™•ç†èˆ‡ API é™åˆ¶è™•ç†** - å¤§è¦æ¨¡æ•¸æ“šåˆ†ææº–å‚™\n",
    "5. **è¼¸å‡ºè§£æå™¨ï¼ˆOutput Parsersï¼‰** - è‡ªå‹•åŒ–çµæœè™•ç†\n",
    "6. **ç®¡é“ç›£æ§èˆ‡èª¿è©¦** - ç¢ºä¿ç®¡é“ç©©å®šé‹è¡Œ\n",
    "\n",
    "è®“æˆ‘å€‘é–‹å§‹æ·±å…¥å­¸ç¿’ LangChain Pipeline çš„æ ¸å¿ƒæŠ€è¡“ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb80d6",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£\n",
    "\n",
    "é¦–å…ˆç¢ºä¿æˆ‘å€‘æœ‰å®Œæ•´çš„ LangChain ç”Ÿæ…‹ç³»çµ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£å®Œæ•´çš„ LangChain ç”Ÿæ…‹ç³»çµ±\n",
    "!pip install langchain langchain-google-genai langchain-community langchain-core python-dotenv pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1190f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡çµ„\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from pydantic import BaseModel, Field  # æ›´æ–°ç‚º Pydantic v2\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=os.getenv(\"MODEL\", \"gemini-1.5-flash\"),\n",
    "    temperature=os.getenv(\"TEMPERATURE\", 0.7),\n",
    "    google_api_key=os.getenv(\"API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548b1c3",
   "metadata": {},
   "source": [
    "## ğŸ¯ æº–å‚™ PromptTemplate\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨ç¬¬ 03 èª²å­¸åˆ°çš„ PromptTemplate æŠ€å·§ä¾†å»ºç«‹ç®¡é“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718e316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PromptTemplate æº–å‚™å®Œæˆ\n",
      "ğŸ¯ ç¾åœ¨é–‹å§‹å­¸ç¿’å¦‚ä½•çµ„åˆæˆç®¡é“\n"
     ]
    }
   ],
   "source": [
    "# æº–å‚™åŸºæœ¬çš„ PromptTemplateï¼ˆä¾†è‡ªç¬¬ 03 èª²ï¼‰\n",
    "basic_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"è«‹å›ç­”ä»¥ä¸‹å•é¡Œï¼š{question}\"\n",
    ")\n",
    "\n",
    "# é£²æ–™å“ç‰Œè­˜åˆ¥ Promptï¼ˆä¾†è‡ªç¬¬ 03 èª²ï¼‰\n",
    "brand_identification_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£é£²æ–™å¸‚å ´åˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œè­˜åˆ¥å…¶ä¸­æåˆ°çš„é£²æ–™å“ç‰Œã€‚\n",
    "\n",
    "æ–‡æœ¬ï¼š{text}\n",
    "\n",
    "è«‹ä»¥ JSON æ ¼å¼è¿”å›çµæœï¼š\n",
    "{{\n",
    "    \"brands\": [\"å“ç‰Œ1\", \"å“ç‰Œ2\", ...],\n",
    "    \"confidence\": \"é«˜/ä¸­/ä½\",\n",
    "    \"reasoning\": \"è­˜åˆ¥ç†ç”±\"\n",
    "}}\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "- åªè­˜åˆ¥å°ç£å¸¸è¦‹çš„é£²æ–™å“ç‰Œï¼ˆå¦‚ï¼šCoCoã€50åµã€è¿·å®¢å¤ã€æ¸…å¿ƒç¦å…¨ç­‰ï¼‰\n",
    "- å¦‚æœæ²’æœ‰æ˜ç¢ºå“ç‰Œï¼Œbrands è¿”å›ç©ºé™£åˆ—\n",
    "- è«‹åˆ¤æ–·è­˜åˆ¥çš„ä¿¡å¿ƒç¨‹åº¦\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… PromptTemplate æº–å‚™å®Œæˆ\")\n",
    "print(\"ğŸ¯ ç¾åœ¨é–‹å§‹å­¸ç¿’å¦‚ä½•çµ„åˆæˆç®¡é“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd78018",
   "metadata": {},
   "source": [
    "## ğŸ”— LangChain ç®¡é“ï¼ˆPipelineï¼‰æ ¸å¿ƒæŠ€è¡“\n",
    "\n",
    "LangChain çš„ç®¡é“ç³»çµ±æ˜¯å…¶æœ€å¼·å¤§çš„ç‰¹æ€§ä¹‹ä¸€ã€‚ä½¿ç”¨ `|` é‹ç®—å­å¯ä»¥è¼•é¬†çµ„åˆä¸åŒçš„çµ„ä»¶ã€‚\n",
    "\n",
    "### ğŸ¯ ç®¡é“è¨­è¨ˆæ¦‚å¿µ\n",
    "\n",
    "ç®¡é“ï¼ˆPipelineï¼‰æ˜¯ LangChain çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "- **æ¨¡çµ„åŒ–è¨­è¨ˆ**: æ¯å€‹çµ„ä»¶éƒ½æœ‰æ˜ç¢ºçš„è·è²¬\n",
    "- **éˆå¼çµ„åˆ**: ä½¿ç”¨ `|` é‹ç®—å­ä¸²æ¥çµ„ä»¶\n",
    "- **æ•¸æ“šæµå‹•**: æ•¸æ“šå¾ä¸€å€‹çµ„ä»¶æµå‘ä¸‹ä¸€å€‹çµ„ä»¶\n",
    "- **éŒ¯èª¤å‚³æ’­**: éŒ¯èª¤æœƒåœ¨ç®¡é“ä¸­å‚³æ’­å’Œè™•ç†\n",
    "\n",
    "è®“æˆ‘å€‘å¾ç°¡å–®çš„ç®¡é“é–‹å§‹å­¸ç¿’ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe45234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— å»ºç«‹åŸºæœ¬ç®¡é“ï¼šPromptTemplate | LLM\n",
      "âœ… åŸºæœ¬ç®¡é“å·²å»ºç«‹\n",
      "ğŸ¯ ç®¡é“çµ„æˆï¼šPromptTemplate â†’ LLM\n",
      "\n",
      "æ¸¬è©¦åŸºæœ¬ç®¡é“ï¼š\n",
      "ğŸ“¤ è¼¸å…¥ï¼šè«‹ç°¡çŸ­ä»‹ç´¹ LangChain\n",
      "ğŸ“¥ è¼¸å‡ºï¼šLangChain æ˜¯ä¸€å€‹ç”¨æ–¼é–‹ç™¼åŸºæ–¼å¤§å‹èªè¨€æ¨¡å‹ (LLM) çš„æ‡‰ç”¨ç¨‹å¼çš„æ¡†æ¶ã€‚ ç°¡å–®ä¾†èªªï¼Œå®ƒæä¾›äº†ä¸€çµ„å·¥å…·ã€çµ„ä»¶å’Œä»‹é¢ï¼Œè®“ä½ å¯ä»¥æ›´æ–¹ä¾¿åœ°ï¼š\n",
      "\n",
      "* **é€£æ¥ LLM èˆ‡å¤–éƒ¨æ•¸æ“šæºï¼š** åƒæ˜¯è³‡æ–™åº«ã€APIã€æ–‡ä»¶ç­‰ç­‰ï¼Œè®“ LLM èƒ½å¤ ç²å–æ›´å¤šè³‡è¨Šã€‚\n",
      "* **æ§‹å»ºè¤‡é›œçš„ LLM æ‡‰ç”¨æµç¨‹ï¼š** ä¾‹å¦‚å•ç­”ç³»çµ±ã€èŠå¤©æ©Ÿå™¨äººã€æ–‡ä»¶æ‘˜è¦ç­‰ç­‰ï¼Œå¯ä»¥å°‡å¤šå€‹ LLM æ“ä½œä¸²è¯èµ·ä¾†ã€‚\n",
      "* **æé«˜ LLM æ‡‰ç”¨ç¨‹å¼çš„å¯è§£é‡‹æ€§å’Œå¯æ§æ€§ï¼š** æ–¹ä¾¿è¿½è¹¤ LLM çš„æ¨ç†éç¨‹ï¼Œä¸¦é€²è¡Œå¹²é å’Œèª¿æ•´ã€‚\n",
      "\n",
      "ç¸½ä¹‹ï¼ŒLangChain è®“é–‹ç™¼è€…æ›´å®¹æ˜“åˆ©ç”¨ LLM çš„å¼·å¤§èƒ½åŠ›ï¼Œæ‰“é€ æ›´æ™ºèƒ½ã€æ›´å¯¦ç”¨çš„æ‡‰ç”¨ç¨‹å¼ã€‚\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. åŸºæœ¬ç®¡é“ï¼šPrompt + LLM\n",
    "print(\"ğŸ”— å»ºç«‹åŸºæœ¬ç®¡é“ï¼šPromptTemplate | LLM\")\n",
    "\n",
    "# å»ºç«‹ç°¡å–®çš„å•ç­”ç®¡é“\n",
    "qa_chain = basic_prompt | llm\n",
    "\n",
    "print(\"âœ… åŸºæœ¬ç®¡é“å·²å»ºç«‹\")\n",
    "print(\"ğŸ¯ ç®¡é“çµ„æˆï¼šPromptTemplate â†’ LLM\")\n",
    "print(\"\\næ¸¬è©¦åŸºæœ¬ç®¡é“ï¼š\")\n",
    "\n",
    "try:\n",
    "    result = qa_chain.invoke({\"question\": \"è«‹ç°¡çŸ­ä»‹ç´¹ LangChain\"})\n",
    "    print(f\"ğŸ“¤ è¼¸å…¥ï¼šè«‹ç°¡çŸ­ä»‹ç´¹ LangChain\")\n",
    "    print(f\"ğŸ“¥ è¼¸å‡ºï¼š{result.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ éŒ¯èª¤ï¼š{e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ce050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— å»ºç«‹é€²éšç®¡é“ï¼šPromptTemplate | LLM | OutputParser\n",
      "âœ… é€²éšç®¡é“å·²å»ºç«‹\n",
      "ğŸ¯ ç®¡é“çµ„æˆï¼šPromptTemplate â†’ LLM â†’ StrOutputParser\n",
      "\n",
      "æ¸¬è©¦é€²éšç®¡é“ï¼š\n",
      "ğŸ“¤ è¼¸å…¥ï¼šç°¡çŸ­æè¿°ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ\n",
      "ğŸ“¥ è¼¸å‡ºé¡å‹ï¼š<class 'str'>\n",
      "ğŸ“¥ è¼¸å‡ºå…§å®¹ï¼šæ©Ÿå™¨å­¸ç¿’æ˜¯ä¸€ç¨®è®“é›»è…¦åœ¨**æ²’æœ‰æ˜ç¢ºç¨‹å¼æŒ‡ä»¤**çš„æƒ…æ³ä¸‹ï¼Œ**å¾æ•¸æ“šä¸­å­¸ç¿’**ï¼Œä¸¦**è‡ªå‹•æ”¹é€²**å…¶æ€§èƒ½çš„æŠ€è¡“ã€‚ ç°¡å–®ä¾†èªªï¼Œå°±æ˜¯è®“é›»è…¦è‡ªå·±æ‰¾è¦å¾‹ï¼Œä¸¦åˆ©ç”¨é€™äº›è¦å¾‹ä¾†åšå‡ºé æ¸¬æˆ–æ±ºç­–ã€‚...\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 2. é€²éšç®¡é“ï¼šPrompt + LLM + Output Parser\n",
    "print(\"ğŸ”— å»ºç«‹é€²éšç®¡é“ï¼šPromptTemplate | LLM | OutputParser\")\n",
    "\n",
    "# å­—ç¬¦ä¸²è¼¸å‡ºè§£æå™¨\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "# å»ºç«‹é€²éšç®¡é“\n",
    "advanced_chain = basic_prompt | llm | str_parser\n",
    "\n",
    "print(\"âœ… é€²éšç®¡é“å·²å»ºç«‹\")\n",
    "print(\"ğŸ¯ ç®¡é“çµ„æˆï¼šPromptTemplate â†’ LLM â†’ StrOutputParser\")\n",
    "print(\"\\næ¸¬è©¦é€²éšç®¡é“ï¼š\")\n",
    "\n",
    "try:\n",
    "    result = advanced_chain.invoke({\"question\": \"ç°¡çŸ­æè¿°ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ\"})\n",
    "    print(f\"ğŸ“¤ è¼¸å…¥ï¼šç°¡çŸ­æè¿°ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ\")\n",
    "    print(f\"ğŸ“¥ è¼¸å‡ºé¡å‹ï¼š{type(result)}\")\n",
    "    print(f\"ğŸ“¥ è¼¸å‡ºå…§å®¹ï¼š{result[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ éŒ¯èª¤ï¼š{e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f76cc",
   "metadata": {},
   "source": [
    "### ğŸ¤” ç‚ºä»€éº¼éœ€è¦ StrOutputParserï¼Ÿ\n",
    "\n",
    "å¾ˆå¤šäººæœƒå•ï¼š**ã€ŒLLM API å›å‚³çš„ä¸æ˜¯å·²ç¶“æ˜¯å­—ä¸²äº†å—ï¼Ÿç‚ºä»€éº¼é‚„éœ€è¦ StrOutputParserï¼Ÿã€**\n",
    "\n",
    "é€™æ˜¯ä¸€å€‹å¾ˆæ£’çš„å•é¡Œï¼è®“æˆ‘å€‘ä¾†çœ‹çœ‹å¯¦éš›çš„æƒ…æ³ï¼š\n",
    "\n",
    "#### ğŸ“‹ LLM å›å‚³çš„å¯¦éš›æ ¼å¼\n",
    "\n",
    "```python\n",
    "# ç›´æ¥èª¿ç”¨ LLM æ™‚ï¼Œè¿”å›çš„æ˜¯ AIMessage ç‰©ä»¶\n",
    "result = llm.invoke(\"ä½ å¥½\")\n",
    "print(type(result))        # <class 'langchain_core.messages.ai.AIMessage'>\n",
    "print(result.content)      # é€™æ‰æ˜¯æˆ‘å€‘è¦çš„å­—ä¸²å…§å®¹\n",
    "```\n",
    "\n",
    "#### ğŸ¯ StrOutputParser çš„ä½œç”¨\n",
    "\n",
    "1. **ç‰©ä»¶è½‰å­—ä¸²**ï¼šå°‡ `AIMessage` ç‰©ä»¶è½‰æ›ç‚ºç´”å­—ä¸²\n",
    "2. **ç®¡é“çµ±ä¸€æ€§**ï¼šç¢ºä¿ç®¡é“ä¸­çš„æ•¸æ“šæ ¼å¼ä¸€è‡´\n",
    "3. **å¾ŒçºŒè™•ç†**ï¼šä¾¿æ–¼é€²è¡Œé€²ä¸€æ­¥çš„å­—ä¸²æ“ä½œ\n",
    "4. **å‹åˆ¥å®‰å…¨**ï¼šæ˜ç¢ºæ•¸æ“šé¡å‹ï¼Œé¿å…æ··æ·†\n",
    "\n",
    "#### ğŸ’¡ å¯¦éš›æ¯”è¼ƒ\n",
    "\n",
    "| æ–¹æ³• | å›å‚³é¡å‹ | å–å¾—å…§å®¹æ–¹å¼ | ç®¡é“å‹å–„åº¦ |\n",
    "|------|----------|--------------|------------|\n",
    "| `llm.invoke()` | `AIMessage` | `result.content` | âŒ éœ€è¦é¡å¤–è™•ç† |\n",
    "| `llm \\| StrOutputParser()` | `str` | ç›´æ¥ä½¿ç”¨ | âœ… å®Œç¾æ•´åˆ |\n",
    "\n",
    "#### ğŸ”— åœ¨ Pipeline ä¸­çš„é‡è¦æ€§\n",
    "\n",
    "```python\n",
    "# âŒ æ²’æœ‰ StrOutputParser - éœ€è¦æ‰‹å‹•è™•ç†\n",
    "chain = prompt | llm\n",
    "result = chain.invoke({\"question\": \"...\"})\n",
    "text = result.content  # éœ€è¦é¡å¤–æ­¥é©Ÿ\n",
    "\n",
    "# âœ… æœ‰ StrOutputParser - ç›´æ¥ç²å¾—å­—ä¸²\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "text = chain.invoke({\"question\": \"...\"})  # ç›´æ¥æ˜¯å­—ä¸²\n",
    "```\n",
    "\n",
    "**çµè«–**ï¼š`StrOutputParser` è®“ç®¡é“æ›´åŠ ç°¡æ½”å’Œä¸€è‡´ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2283a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ è¤‡é›œç®¡é“ä¸­çš„ StrOutputParser é‡è¦æ€§\n",
      "==================================================\n",
      "\n",
      "âœ… æœ‰ StrOutputParser çš„ç®¡é“ï¼š\n",
      "âœ… æˆåŠŸåŸ·è¡Œï¼\n",
      "ğŸ“Š çµ±è¨ˆçµæœï¼š\n",
      "   åŸæ–‡é•·åº¦ï¼š50 å­—ç¬¦\n",
      "   å–®è©æ•¸é‡ï¼š1 å€‹\n",
      "   ç„¡ç©ºæ ¼å­—ç¬¦ï¼š50 å€‹\n",
      "   æ¸…ç†å¾Œå…§å®¹ï¼šç¨‹å¼è¨­è¨ˆæ˜¯æŒ‡ä½¿ç”¨ç‰¹å®šçš„ç¨‹å¼èªè¨€æ’°å¯«æŒ‡ä»¤è®“é›»è…¦åŸ·è¡Œç‰¹å®šä»»å‹™æˆ–è§£æ±ºå•é¡Œçš„éç¨‹ç°¡å–®ä¾†èªªå°±æ˜¯å‘Šè¨´é›»è…¦è¦åšä»€éº¼...\n",
      "\n",
      "   ğŸ’¥ æ²’æœ‰ StrOutputParserï¼šå¾ŒçºŒå‡½æ•¸æœƒæ”¶åˆ°éŒ¯èª¤çš„æ•¸æ“šé¡å‹\n",
      "   âœ… æœ‰ StrOutputParserï¼šæ•¸æ“šé¡å‹çµ±ä¸€ï¼Œç®¡é“é †æš¢é‹è¡Œ\n",
      "   ğŸ“ é€™åœ¨å»ºç«‹è¤‡é›œç®¡é“æ™‚ç‰¹åˆ¥é‡è¦ï¼\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ é€²éšç¯„ä¾‹ï¼šStrOutputParser åœ¨è¤‡é›œç®¡é“ä¸­çš„é‡è¦æ€§\n",
    "print(\"ğŸ”§ è¤‡é›œç®¡é“ä¸­çš„ StrOutputParser é‡è¦æ€§\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# å‡è¨­æˆ‘å€‘è¦å»ºç«‹ä¸€å€‹ï¼šå•ç­” â†’ æ–‡å­—æ¸…ç† â†’ é•·åº¦çµ±è¨ˆ çš„ç®¡é“\n",
    "\n",
    "def text_cleaner(text):\n",
    "    \"\"\"æ–‡å­—æ¸…ç†å‡½æ•¸ï¼šç§»é™¤å¤šé¤˜ç©ºæ ¼å’Œæ¨™é»\"\"\"\n",
    "    if hasattr(text, 'content'):  # å¦‚æœæ˜¯ AIMessage ç‰©ä»¶\n",
    "        text = text.content\n",
    "    # æ¸…ç†æ–‡å­—\n",
    "    cleaned = re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "def text_stats(text):\n",
    "    \"\"\"çµ±è¨ˆæ–‡å­—é•·åº¦\"\"\"\n",
    "    return {\n",
    "        'original': text,\n",
    "        'length': len(text),\n",
    "        'words': len(text.split()),\n",
    "        'chars_no_space': len(text.replace(' ', ''))\n",
    "    }\n",
    "\n",
    "print()\n",
    "\n",
    "# âœ… æœ‰ StrOutputParser çš„ç®¡é“\n",
    "print(\"âœ… æœ‰ StrOutputParser çš„ç®¡é“ï¼š\")\n",
    "try:\n",
    "    working_chain = (\n",
    "        basic_prompt | \n",
    "        llm |\n",
    "        StrOutputParser() |  # å°‡ AIMessage è½‰ç‚ºå­—ä¸²\n",
    "        RunnableLambda(text_cleaner) |\n",
    "        RunnableLambda(text_stats)\n",
    "    )\n",
    "    \n",
    "    result = working_chain.invoke({\"question\": \"ç°¡çŸ­æè¿°ä»€éº¼æ˜¯ç¨‹å¼è¨­è¨ˆï¼Ÿ\"})\n",
    "    print(f\"âœ… æˆåŠŸåŸ·è¡Œï¼\")\n",
    "    print(f\"ğŸ“Š çµ±è¨ˆçµæœï¼š\")\n",
    "    print(f\"   åŸæ–‡é•·åº¦ï¼š{result['length']} å­—ç¬¦\")\n",
    "    print(f\"   å–®è©æ•¸é‡ï¼š{result['words']} å€‹\")\n",
    "    print(f\"   ç„¡ç©ºæ ¼å­—ç¬¦ï¼š{result['chars_no_space']} å€‹\")\n",
    "    print(f\"   æ¸…ç†å¾Œå…§å®¹ï¼š{result['original'][:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ éŒ¯èª¤ï¼š{e}\")\n",
    "\n",
    "print()\n",
    "print(\"   ğŸ’¥ æ²’æœ‰ StrOutputParserï¼šå¾ŒçºŒå‡½æ•¸æœƒæ”¶åˆ°éŒ¯èª¤çš„æ•¸æ“šé¡å‹\")\n",
    "print(\"   âœ… æœ‰ StrOutputParserï¼šæ•¸æ“šé¡å‹çµ±ä¸€ï¼Œç®¡é“é †æš¢é‹è¡Œ\")\n",
    "print(\"   ğŸ“ é€™åœ¨å»ºç«‹è¤‡é›œç®¡é“æ™‚ç‰¹åˆ¥é‡è¦ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c37f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸª å»ºç«‹å“ç‰Œè­˜åˆ¥ç®¡é“\n",
      "âœ… å“ç‰Œè­˜åˆ¥ç®¡é“å·²å»ºç«‹\n",
      "ğŸ¯ ç®¡é“çµ„æˆï¼šå“ç‰Œè­˜åˆ¥Prompt â†’ LLM â†’ å­—ç¬¦ä¸²è§£æå™¨\n",
      "\n",
      "æ¸¬è©¦å“ç‰Œè­˜åˆ¥ç®¡é“ï¼š\n",
      "ğŸ“¤ è¼¸å…¥æ–‡æœ¬ï¼šæ˜¨å¤©å» CoCo è²·äº†ç„¦ç³–å¥¶èŒ¶ï¼Œä»Šå¤©æƒ³è©¦è©¦çœ‹ 50åµ çš„æ³¢éœ¸å¥¶èŒ¶ã€‚æœ‹å‹æ¨è–¦è¿·å®¢å¤çš„èŠèŠç³»åˆ—ä¹Ÿå¾ˆæ£’ã€‚\n",
      "ğŸ“¥ LLM åŸå§‹è¼¸å‡ºï¼š```json\n",
      "{\n",
      "    \"brands\": [\"CoCo\", \"50åµ\", \"è¿·å®¢å¤\"],\n",
      "    \"confidence\": \"é«˜\",\n",
      "    \"reasoning\": \"æ–‡æœ¬ä¸­æ˜ç¢ºæåŠCoCoã€50åµã€è¿·å®¢å¤ä¸‰å€‹å°ç£å¸¸è¦‹çš„é£²æ–™å“ç‰Œã€‚\"\n",
      "}\n",
      "```\n",
      "\n",
      "âœ… JSON è§£ææˆåŠŸï¼š\n",
      "ğŸª è­˜åˆ¥çš„å“ç‰Œï¼š['CoCo', '50åµ', 'è¿·å®¢å¤']\n",
      "ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜\n",
      "ğŸ§  è­˜åˆ¥ç†ç”±ï¼šæ–‡æœ¬ä¸­æ˜ç¢ºæåŠCoCoã€50åµã€è¿·å®¢å¤ä¸‰å€‹å°ç£å¸¸è¦‹çš„é£²æ–™å“ç‰Œã€‚\n"
     ]
    }
   ],
   "source": [
    "# 3. å¯¦æˆ°ç®¡é“ï¼šå“ç‰Œè­˜åˆ¥ç®¡é“\n",
    "print(\"ğŸª å»ºç«‹å“ç‰Œè­˜åˆ¥ç®¡é“\")\n",
    "\n",
    "# å»ºç«‹å“ç‰Œè­˜åˆ¥éˆ\n",
    "brand_identification_chain = brand_identification_prompt | llm | str_parser\n",
    "\n",
    "print(\"âœ… å“ç‰Œè­˜åˆ¥ç®¡é“å·²å»ºç«‹\")\n",
    "print(\"ğŸ¯ ç®¡é“çµ„æˆï¼šå“ç‰Œè­˜åˆ¥Prompt â†’ LLM â†’ å­—ç¬¦ä¸²è§£æå™¨\")\n",
    "print(\"\\næ¸¬è©¦å“ç‰Œè­˜åˆ¥ç®¡é“ï¼š\")\n",
    "\n",
    "test_text = \"æ˜¨å¤©å» CoCo è²·äº†ç„¦ç³–å¥¶èŒ¶ï¼Œä»Šå¤©æƒ³è©¦è©¦çœ‹ 50åµ çš„æ³¢éœ¸å¥¶èŒ¶ã€‚æœ‹å‹æ¨è–¦è¿·å®¢å¤çš„èŠèŠç³»åˆ—ä¹Ÿå¾ˆæ£’ã€‚\"\n",
    "\n",
    "try:\n",
    "    result = brand_identification_chain.invoke({\"text\": test_text})\n",
    "    print(f\"ğŸ“¤ è¼¸å…¥æ–‡æœ¬ï¼š{test_text}\")\n",
    "    print(f\"ğŸ“¥ LLM åŸå§‹è¼¸å‡ºï¼š{result}\")\n",
    "    \n",
    "    # å˜—è©¦è§£æ JSON\n",
    "    try:\n",
    "        # æ¸…ç†å¯èƒ½çš„ä»£ç¢¼å€å¡ŠåŒ…è£\n",
    "        cleaned_result = result.strip()\n",
    "        if cleaned_result.startswith('```json'):\n",
    "            cleaned_result = cleaned_result.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        parsed = json.loads(cleaned_result)\n",
    "        print(f\"\\nâœ… JSON è§£ææˆåŠŸï¼š\")\n",
    "        print(f\"ğŸª è­˜åˆ¥çš„å“ç‰Œï¼š{parsed.get('brands', [])}\")\n",
    "        print(f\"ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼š{parsed.get('confidence', 'N/A')}\")\n",
    "        print(f\"ğŸ§  è­˜åˆ¥ç†ç”±ï¼š{parsed.get('reasoning', 'N/A')}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"âš ï¸ JSON è§£æå¤±æ•—ï¼Œé€™å°±æ˜¯ç‚ºä»€éº¼æˆ‘å€‘éœ€è¦å¥å£¯çš„éŒ¯èª¤è™•ç†ï¼\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç®¡é“åŸ·è¡ŒéŒ¯èª¤ï¼š{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4247c",
   "metadata": {},
   "source": [
    "## ğŸ“Š çµæ§‹åŒ–è¼¸å‡ºèˆ‡ JSON è§£æ\n",
    "\n",
    "åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæˆ‘å€‘éœ€è¦ LLM è¿”å›çµæ§‹åŒ–çš„æ•¸æ“šã€‚\n",
    "\n",
    "### ğŸ¯ ç‚ºä»€éº¼éœ€è¦çµæ§‹åŒ–è¼¸å‡ºï¼Ÿ\n",
    "\n",
    "1. **ç¨‹å¼åŒ–è™•ç†**: çµæ§‹åŒ–æ•¸æ“šä¾¿æ–¼ç¨‹å¼è™•ç†\n",
    "2. **æ•¸æ“šé©—è­‰**: å¯ä»¥é©—è­‰è¼¸å‡ºæ ¼å¼çš„æ­£ç¢ºæ€§\n",
    "3. **æ‰¹é‡åˆ†æ**: æ”¯æ´å¤§è¦æ¨¡æ•¸æ“šåˆ†æ\n",
    "4. **çµæœçµ±è¨ˆ**: ä¾¿æ–¼é€²è¡Œçµ±è¨ˆå’Œè¦–è¦ºåŒ–\n",
    "\n",
    "è®“æˆ‘å€‘å­¸ç¿’å¦‚ä½•å¯¦ç¾ç©©å®šçš„çµæ§‹åŒ–è¼¸å‡ºï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c811c2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å®šç¾©äº† BrandAnalysis çµæ§‹\n",
      "âœ… é€™å°‡ç¢ºä¿ LLM è¼¸å‡ºç¬¦åˆæˆ‘å€‘çš„éœ€æ±‚\n",
      "\n",
      "ğŸ—ï¸ è¼¸å‡ºçµæ§‹ï¼š\n",
      "â€¢ brands: è­˜åˆ¥å‡ºçš„é£²æ–™å“ç‰Œåˆ—è¡¨\n",
      "â€¢ confidence: è­˜åˆ¥ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜/ä¸­/ä½\n",
      "â€¢ reasoning: è­˜åˆ¥ç†ç”±\n"
     ]
    }
   ],
   "source": [
    "# 1. å®šç¾©è¼¸å‡ºçµæ§‹\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class BrandAnalysis(BaseModel):\n",
    "    \"\"\"å“ç‰Œåˆ†æçµæœçš„çµæ§‹å®šç¾©\"\"\"\n",
    "    brands: List[str] = Field(description=\"è­˜åˆ¥å‡ºçš„é£²æ–™å“ç‰Œåˆ—è¡¨\")\n",
    "    confidence: str = Field(description=\"è­˜åˆ¥ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜/ä¸­/ä½\")\n",
    "    reasoning: str = Field(description=\"è­˜åˆ¥ç†ç”±\")\n",
    "\n",
    "print(\"ğŸ“‹ å®šç¾©äº† BrandAnalysis çµæ§‹\")\n",
    "print(\"âœ… é€™å°‡ç¢ºä¿ LLM è¼¸å‡ºç¬¦åˆæˆ‘å€‘çš„éœ€æ±‚\")\n",
    "\n",
    "# å±•ç¤ºçµæ§‹\n",
    "print(\"\\nğŸ—ï¸ è¼¸å‡ºçµæ§‹ï¼š\")\n",
    "print(f\"â€¢ brands: {BrandAnalysis.model_fields['brands'].description}\")\n",
    "print(f\"â€¢ confidence: {BrandAnalysis.model_fields['confidence'].description}\")\n",
    "print(f\"â€¢ reasoning: {BrandAnalysis.model_fields['reasoning'].description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4748fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ å»ºç«‹ JSON è¼¸å‡ºè§£æå™¨\n",
      "ğŸ“‹ ç²å–æ ¼å¼èªªæ˜ï¼š\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"å“ç‰Œåˆ†æçµæœçš„çµæ§‹å®šç¾©\", \"properties\": {\"brands\": {\"description\": \"è­˜åˆ¥å‡ºçš„é£²æ–™å“ç‰Œåˆ—è¡¨\", \"items\": {\"type\": \"string\"}, \"title\": \"Brands\", \"type\": \"array\"}, \"confidence\": {\"description\": \"è­˜åˆ¥ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜/ä¸­/ä½\", \"title\": \"Confidence\", \"type\": \"string\"}, \"reasoning\": {\"description\": \"è­˜åˆ¥ç†ç”±\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"brands\", \"confidence\", \"reasoning\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 2. ä½¿ç”¨ JsonOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# å»ºç«‹ JSON è§£æå™¨\n",
    "json_parser = JsonOutputParser(pydantic_object=BrandAnalysis)\n",
    "\n",
    "print(\"ğŸ”§ å»ºç«‹ JSON è¼¸å‡ºè§£æå™¨\")\n",
    "print(\"ğŸ“‹ ç²å–æ ¼å¼èªªæ˜ï¼š\")\n",
    "print(json_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8303c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ”¹é€²çš„çµæ§‹åŒ– Prompt å·²å®šç¾©\n",
      "ğŸ¯ åŒ…å«äº†è‡ªå‹•ç”Ÿæˆçš„æ ¼å¼èªªæ˜\n"
     ]
    }
   ],
   "source": [
    "# 3. æ”¹é€²çš„å“ç‰Œè­˜åˆ¥ Promptï¼ˆåŒ…å«æ ¼å¼èªªæ˜ï¼‰\n",
    "structured_brand_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£é£²æ–™å¸‚å ´åˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œè­˜åˆ¥å…¶ä¸­æåˆ°çš„é£²æ–™å“ç‰Œã€‚\n",
    "\n",
    "æ–‡æœ¬ï¼š{text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "æ³¨æ„ï¼š\n",
    "- åªè­˜åˆ¥å°ç£å¸¸è¦‹çš„é£²æ–™å“ç‰Œï¼ˆå¦‚ï¼šCoCoã€50åµã€è¿·å®¢å¤ã€æ¸…å¿ƒç¦å…¨ç­‰ï¼‰\n",
    "- å¦‚æœæ²’æœ‰æ˜ç¢ºå“ç‰Œï¼Œbrands è¿”å›ç©ºé™£åˆ—\n",
    "- confidence è«‹å¡«å…¥ï¼šé«˜/ä¸­/ä½\n",
    "\"\"\",\n",
    "    partial_variables={\"format_instructions\": json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(\"âœ… æ”¹é€²çš„çµæ§‹åŒ– Prompt å·²å®šç¾©\")\n",
    "print(\"ğŸ¯ åŒ…å«äº†è‡ªå‹•ç”Ÿæˆçš„æ ¼å¼èªªæ˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e72dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— å»ºç«‹çµæ§‹åŒ–å“ç‰Œåˆ†æç®¡é“\n",
      "ğŸ¯ ç®¡é“çµ„æˆï¼šçµæ§‹åŒ–Prompt â†’ LLM â†’ JSONè§£æå™¨\n",
      "\n",
      "ğŸ“¤ æ¸¬è©¦æ–‡æœ¬ï¼šä»Šå¤©å¿ƒæƒ…ä¸éŒ¯ï¼Œå…ˆå» CoCo è²·äº†çç å¥¶èŒ¶ï¼Œä¸‹åˆåˆå» 50åµ è²·äº†æ³¢éœ¸å¥¶èŒ¶ã€‚æ™šä¸Šæœ‹å‹æ¨è–¦å»è¿·å®¢å¤è©¦è©¦çœ‹èŠèŠç³»åˆ—ã€‚\n",
      "\n",
      "âœ… çµæ§‹åŒ–è¼¸å‡ºæˆåŠŸï¼š\n",
      "ğŸ“Š è¼¸å‡ºé¡å‹ï¼š<class 'dict'>\n",
      "ğŸª è­˜åˆ¥å“ç‰Œï¼š['CoCo', '50åµ', 'è¿·å®¢å¤']\n",
      "ğŸ“ˆ ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜\n",
      "ğŸ§  åˆ†æç†ç”±ï¼šæ–‡æœ¬ä¸­æ˜ç¢ºæåŠCoCoã€50åµå’Œè¿·å®¢å¤ï¼Œçš†ç‚ºå°ç£å¸¸è¦‹ä¸”çŸ¥åçš„é€£é–é£²æ–™å“ç‰Œã€‚\n"
     ]
    }
   ],
   "source": [
    "# 4. å»ºç«‹çµæ§‹åŒ–è¼¸å‡ºç®¡é“\n",
    "structured_brand_chain = structured_brand_prompt | llm | json_parser\n",
    "\n",
    "print(\"ğŸ”— å»ºç«‹çµæ§‹åŒ–å“ç‰Œåˆ†æç®¡é“\")\n",
    "print(\"ğŸ¯ ç®¡é“çµ„æˆï¼šçµæ§‹åŒ–Prompt â†’ LLM â†’ JSONè§£æå™¨\")\n",
    "\n",
    "# æ¸¬è©¦çµæ§‹åŒ–è¼¸å‡º\n",
    "test_text = \"ä»Šå¤©å¿ƒæƒ…ä¸éŒ¯ï¼Œå…ˆå» CoCo è²·äº†çç å¥¶èŒ¶ï¼Œä¸‹åˆåˆå» 50åµ è²·äº†æ³¢éœ¸å¥¶èŒ¶ã€‚æ™šä¸Šæœ‹å‹æ¨è–¦å»è¿·å®¢å¤è©¦è©¦çœ‹èŠèŠç³»åˆ—ã€‚\"\n",
    "\n",
    "print(f\"\\nğŸ“¤ æ¸¬è©¦æ–‡æœ¬ï¼š{test_text}\")\n",
    "\n",
    "try:\n",
    "    result = structured_brand_chain.invoke({\"text\": test_text})\n",
    "    print(\"\\nâœ… çµæ§‹åŒ–è¼¸å‡ºæˆåŠŸï¼š\")\n",
    "    print(f\"ğŸ“Š è¼¸å‡ºé¡å‹ï¼š{type(result)}\")\n",
    "    print(f\"ğŸª è­˜åˆ¥å“ç‰Œï¼š{result.get('brands', [])}\")\n",
    "    print(f\"ğŸ“ˆ ä¿¡å¿ƒç¨‹åº¦ï¼š{result.get('confidence', 'N/A')}\")\n",
    "    print(f\"ğŸ§  åˆ†æç†ç”±ï¼š{result.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ çµæ§‹åŒ–è¼¸å‡ºå¤±æ•—ï¼š{e}\")\n",
    "    print(\"ğŸ’¡ é€™å°±æ˜¯ç‚ºä»€éº¼æˆ‘å€‘éœ€è¦å®¹éŒ¯æ©Ÿåˆ¶ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28960a4b",
   "metadata": {},
   "source": [
    "## ğŸ›¡ï¸ éŒ¯èª¤è™•ç†èˆ‡å®¹éŒ¯æ©Ÿåˆ¶\n",
    "\n",
    "åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œç©©å®šæ€§è‡³é—œé‡è¦ã€‚è®“æˆ‘å€‘å­¸ç¿’å¦‚ä½•å»ºç«‹å¥å£¯çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ed95ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶å·²å®šç¾©\n",
      "âœ… åŒ…å«é‡è©¦æ©Ÿåˆ¶å’Œå‚™ç”¨åˆ†ææ–¹æ³•\n"
     ]
    }
   ],
   "source": [
    "# 1. åŸºæœ¬éŒ¯èª¤è™•ç†\n",
    "def safe_brand_analysis(text: str, max_retries: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"å®‰å…¨çš„å“ç‰Œåˆ†æå‡½æ•¸ï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰...\")\n",
    "            \n",
    "            # ä½¿ç”¨çµæ§‹åŒ–ç®¡é“\n",
    "            result = structured_brand_chain.invoke({\"text\": text})\n",
    "            \n",
    "            # é©—è­‰çµæœ\n",
    "            if isinstance(result, dict) and 'brands' in result:\n",
    "                print(\"âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\")\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"è¼¸å‡ºæ ¼å¼ä¸æ­£ç¢º\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âš ï¸ JSON è§£æå¤±æ•—ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰ï¼š{e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return _fallback_analysis(text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ†æå¤±æ•—ï¼ˆç¬¬ {attempt + 1} æ¬¡ï¼‰ï¼š{e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return _fallback_analysis(text)\n",
    "            \n",
    "        # é‡è©¦å‰ç­‰å¾…\n",
    "        if attempt < max_retries - 1:\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return _fallback_analysis(text)\n",
    "\n",
    "def _fallback_analysis(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"å‚™ç”¨åˆ†ææ–¹æ³•ï¼šä½¿ç”¨ç°¡å–®çš„é—œéµå­—åŒ¹é…\"\"\"\n",
    "    print(\"ğŸ”„ ä½¿ç”¨å‚™ç”¨åˆ†ææ–¹æ³•...\")\n",
    "    \n",
    "    # å¸¸è¦‹å°ç£é£²æ–™å“ç‰Œé—œéµå­—\n",
    "    brand_keywords = [\n",
    "        'CoCo', '50åµ', 'è¿·å®¢å¤', 'æ¸…å¿ƒç¦å…¨', 'éº¥å‰', 'Comebuy', \n",
    "        'èŒ¶æ¹¯æœƒ', 'ä¸€èŠ³', 'é®®èŒ¶é“', 'å¤§è‹‘å­', 'Mr.Wish'\n",
    "    ]\n",
    "    \n",
    "    found_brands = []\n",
    "    for brand in brand_keywords:\n",
    "        if brand in text:\n",
    "            found_brands.append(brand)\n",
    "    \n",
    "    return {\n",
    "        'brands': found_brands,\n",
    "        'confidence': 'ä½',\n",
    "        'reasoning': 'ä½¿ç”¨å‚™ç”¨é—œéµå­—åŒ¹é…æ–¹æ³•'\n",
    "    }\n",
    "\n",
    "print(\"ğŸ›¡ï¸ éŒ¯èª¤è™•ç†æ©Ÿåˆ¶å·²å®šç¾©\")\n",
    "print(\"âœ… åŒ…å«é‡è©¦æ©Ÿåˆ¶å’Œå‚™ç”¨åˆ†ææ–¹æ³•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c745ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª æ¸¬è©¦éŒ¯èª¤è™•ç†æ©Ÿåˆ¶\n",
      "\n",
      "ğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ 1ï¼šæ˜¨å¤©å» CoCo è²·äº†çç å¥¶èŒ¶ï¼Œå¾ˆå¥½å–ï¼\n",
      "----------------------------------------\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "ğŸª è­˜åˆ¥å“ç‰Œï¼š['CoCo']\n",
      "ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜\n",
      "ğŸ§  åˆ†æç†ç”±ï¼šæ–‡æœ¬ä¸­æ˜ç¢ºæåŠ 'CoCo'ï¼Œé€™æ˜¯åœ¨å°ç£å»£ç‚ºäººçŸ¥çš„é£²æ–™å“ç‰Œåç¨±ã€‚\n",
      "\n",
      "ğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ 2ï¼šæ¨è–¦ 50åµ çš„æ³¢éœ¸å¥¶èŒ¶å’Œè¿·å®¢å¤çš„èŠèŠç³»åˆ—\n",
      "----------------------------------------\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "ğŸª è­˜åˆ¥å“ç‰Œï¼š['50åµ', 'è¿·å®¢å¤']\n",
      "ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜\n",
      "ğŸ§  åˆ†æç†ç”±ï¼šæ–‡æœ¬ä¸­æ˜ç¢ºæåŠäº†'50åµ'å’Œ'è¿·å®¢å¤'é€™å…©å€‹å°ç£å¸¸è¦‹çš„é£²æ–™å“ç‰Œã€‚\n",
      "\n",
      "ğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ 3ï¼šä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œä½†æ²’æœ‰æåˆ°ä»»ä½•é£²æ–™å“ç‰Œ\n",
      "----------------------------------------\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "ğŸª è­˜åˆ¥å“ç‰Œï¼š[]\n",
      "ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼šé«˜\n",
      "ğŸ§  åˆ†æç†ç”±ï¼šæ–‡æœ¬ä¸­æ²’æœ‰æåŠä»»ä½•é£²æ–™å“ç‰Œã€‚\n",
      "\n",
      "ğŸ¯ é€™ç¨®å¥å£¯çš„éŒ¯èª¤è™•ç†å°‡ç¢ºä¿ç©©å®šæ€§ï¼\n"
     ]
    }
   ],
   "source": [
    "# 2. æ¸¬è©¦éŒ¯èª¤è™•ç†æ©Ÿåˆ¶\n",
    "print(\"ğŸ§ª æ¸¬è©¦éŒ¯èª¤è™•ç†æ©Ÿåˆ¶\")\n",
    "\n",
    "test_cases = [\n",
    "    \"æ˜¨å¤©å» CoCo è²·äº†çç å¥¶èŒ¶ï¼Œå¾ˆå¥½å–ï¼\",\n",
    "    \"æ¨è–¦ 50åµ çš„æ³¢éœ¸å¥¶èŒ¶å’Œè¿·å®¢å¤çš„èŠèŠç³»åˆ—\",\n",
    "    \"ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œä½†æ²’æœ‰æåˆ°ä»»ä½•é£²æ–™å“ç‰Œ\"\n",
    "]\n",
    "\n",
    "for i, test_text in enumerate(test_cases, 1):\n",
    "    print(f\"\\nğŸ“‹ æ¸¬è©¦æ¡ˆä¾‹ {i}ï¼š{test_text}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    result = safe_brand_analysis(test_text)\n",
    "    \n",
    "    print(f\"ğŸª è­˜åˆ¥å“ç‰Œï¼š{result['brands']}\")\n",
    "    print(f\"ğŸ“Š ä¿¡å¿ƒç¨‹åº¦ï¼š{result['confidence']}\")\n",
    "    print(f\"ğŸ§  åˆ†æç†ç”±ï¼š{result['reasoning']}\")\n",
    "\n",
    "print(\"\\nğŸ¯ é€™ç¨®å¥å£¯çš„éŒ¯èª¤è™•ç†å°‡ç¢ºä¿ç©©å®šæ€§ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc0e44",
   "metadata": {},
   "source": [
    "## âš¡ æ‰¹é‡è™•ç†èˆ‡ API é™åˆ¶è™•ç†\n",
    "\n",
    "åœ¨è™•ç†å¤§é‡æ•¸æ“šæ™‚ï¼Œæˆ‘å€‘éœ€è¦è€ƒæ…® API é™åˆ¶å’Œæ•ˆç‡ã€‚\n",
    "\n",
    "### ğŸ¯ æ‰¹é‡è™•ç†çš„é‡è¦æ€§\n",
    "\n",
    "1. **æ•ˆç‡æå‡**: æ‰¹é‡è™•ç†æ¸›å°‘é–‹éŠ·\n",
    "2. **API é™åˆ¶**: é¿å…è¶…é API èª¿ç”¨é™åˆ¶\n",
    "3. **éŒ¯èª¤æ¢å¾©**: å–®å€‹å¤±æ•—ä¸å½±éŸ¿æ•´é«”\n",
    "4. **é€²åº¦è¿½è¹¤**: å¯¦æ™‚ç›£æ§è™•ç†é€²åº¦\n",
    "5. **è³‡æºç®¡ç†**: åˆç†ä½¿ç”¨ç³»çµ±è³‡æº\n",
    "\n",
    "è®“æˆ‘å€‘å­¸ç¿’å¦‚ä½•è¨­è¨ˆå¥å£¯çš„æ‰¹é‡è™•ç†ç³»çµ±ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd5868aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ æ‰¹é‡è™•ç†æ©Ÿåˆ¶å·²å®šç¾©\n",
      "âœ… åŒ…å«é€Ÿç‡é™åˆ¶å’ŒéŒ¯èª¤è™•ç†\n"
     ]
    }
   ],
   "source": [
    "# 1. æ‰¹é‡è™•ç†å‡½æ•¸\n",
    "def batch_brand_analysis(texts: List[str], batch_size: int = 5, delay: float = 1.0) -> List[Dict[str, Any]]:\n",
    "    \"\"\"æ‰¹é‡å“ç‰Œåˆ†æï¼ŒåŒ…å«é€Ÿç‡é™åˆ¶\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    total = len(texts)\n",
    "    \n",
    "    print(f\"ğŸš€ é–‹å§‹æ‰¹é‡åˆ†æ {total} å€‹æ–‡æœ¬\")\n",
    "    print(f\"âš™ï¸ æ‰¹æ¬¡å¤§å°ï¼š{batch_size}ï¼Œå»¶é²ï¼š{delay}ç§’\")\n",
    "    \n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        print(f\"\\nğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_num}/{(total - 1) // batch_size + 1}\")\n",
    "        \n",
    "        for j, text in enumerate(batch):\n",
    "            text_num = i + j + 1\n",
    "            print(f\"  ğŸ“ åˆ†ææ–‡æœ¬ {text_num}/{total}: {text[:30]}...\")\n",
    "            \n",
    "            try:\n",
    "                result = safe_brand_analysis(text, max_retries=2)\n",
    "                result['text_id'] = text_num\n",
    "                result['original_text'] = text\n",
    "                results.append(result)\n",
    "                \n",
    "                print(f\"  âœ… å®Œæˆï¼š{result['brands']}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ å¤±æ•—ï¼š{e}\")\n",
    "                results.append({\n",
    "                    'text_id': text_num,\n",
    "                    'original_text': text,\n",
    "                    'brands': [],\n",
    "                    'confidence': 'ç„¡',\n",
    "                    'reasoning': f'è™•ç†å¤±æ•—ï¼š{str(e)}'\n",
    "                })\n",
    "            \n",
    "            # API é™åˆ¶å»¶é²\n",
    "            if j < len(batch) - 1:  # ä¸æ˜¯æ‰¹æ¬¡çš„æœ€å¾Œä¸€å€‹\n",
    "                time.sleep(delay)\n",
    "        \n",
    "        # æ‰¹æ¬¡é–“å»¶é²\n",
    "        if i + batch_size < total:\n",
    "            print(f\"  â¸ï¸ æ‰¹æ¬¡å®Œæˆï¼Œç­‰å¾… {delay * 2} ç§’...\")\n",
    "            time.sleep(delay * 2)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼æˆåŠŸè™•ç† {len(results)} å€‹æ–‡æœ¬\")\n",
    "    return results\n",
    "\n",
    "print(\"âš¡ æ‰¹é‡è™•ç†æ©Ÿåˆ¶å·²å®šç¾©\")\n",
    "print(\"âœ… åŒ…å«é€Ÿç‡é™åˆ¶å’ŒéŒ¯èª¤è™•ç†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19d1461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª æ¸¬è©¦æ‰¹é‡è™•ç†\n",
      "ğŸš€ é–‹å§‹æ‰¹é‡åˆ†æ 6 å€‹æ–‡æœ¬\n",
      "âš™ï¸ æ‰¹æ¬¡å¤§å°ï¼š3ï¼Œå»¶é²ï¼š0.5ç§’\n",
      "\n",
      "ğŸ“¦ è™•ç†æ‰¹æ¬¡ 1/2\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 1/6: ä»Šå¤©å» CoCo è²·çç å¥¶èŒ¶...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š['CoCo']\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 2/6: 50åµ çš„æ³¢éœ¸å¥¶èŒ¶å¾ˆæ£’...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š['50åµ']\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 3/6: è¿·å®¢å¤çš„èŠèŠç³»åˆ—æ¨è–¦...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š['è¿·å®¢å¤']\n",
      "  â¸ï¸ æ‰¹æ¬¡å®Œæˆï¼Œç­‰å¾… 1.0 ç§’...\n",
      "\n",
      "ğŸ“¦ è™•ç†æ‰¹æ¬¡ 2/2\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 4/6: æ¸…å¿ƒç¦å…¨çš„æª¸æª¬ç¶ èŒ¶...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š['æ¸…å¿ƒç¦å…¨']\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 5/6: ä»Šå¤©å¤©æ°£å¾ˆå¥½ä½†æ²’å–é£²æ–™...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š[]\n",
      "  ğŸ“ åˆ†ææ–‡æœ¬ 6/6: éº¥å‰çš„æ°£æ³¡é£²æ–™å¾ˆç‰¹åˆ¥...\n",
      "ğŸ”„ å˜—è©¦åˆ†æï¼ˆç¬¬ 1 æ¬¡ï¼‰...\n",
      "âœ… çµæ§‹åŒ–åˆ†ææˆåŠŸ\n",
      "  âœ… å®Œæˆï¼š['éº¥å‰']\n",
      "\n",
      "ğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼æˆåŠŸè™•ç† 6 å€‹æ–‡æœ¬\n",
      "\n",
      "ğŸ“Š æ‰¹é‡åˆ†æçµæœçµ±è¨ˆï¼š\n",
      "ğŸª ç¸½å…±è­˜åˆ¥å‡º 5 å€‹ä¸åŒå“ç‰Œ\n",
      "ğŸ“ˆ å“ç‰Œçµ±è¨ˆï¼š{'CoCo': 1, '50åµ': 1, 'è¿·å®¢å¤': 1, 'æ¸…å¿ƒç¦å…¨': 1, 'éº¥å‰': 1}\n",
      "âœ… æˆåŠŸç‡ï¼š83.3%\n"
     ]
    }
   ],
   "source": [
    "# 2. æ¸¬è©¦æ‰¹é‡è™•ç†\n",
    "print(\"ğŸ§ª æ¸¬è©¦æ‰¹é‡è™•ç†\")\n",
    "\n",
    "sample_texts = [\n",
    "    \"ä»Šå¤©å» CoCo è²·çç å¥¶èŒ¶\",\n",
    "    \"50åµ çš„æ³¢éœ¸å¥¶èŒ¶å¾ˆæ£’\",\n",
    "    \"è¿·å®¢å¤çš„èŠèŠç³»åˆ—æ¨è–¦\",\n",
    "    \"æ¸…å¿ƒç¦å…¨çš„æª¸æª¬ç¶ èŒ¶\",\n",
    "    \"ä»Šå¤©å¤©æ°£å¾ˆå¥½ä½†æ²’å–é£²æ–™\",\n",
    "    \"éº¥å‰çš„æ°£æ³¡é£²æ–™å¾ˆç‰¹åˆ¥\"\n",
    "]\n",
    "\n",
    "# åŸ·è¡Œæ‰¹é‡åˆ†æï¼ˆè¼ƒå°çš„å»¶é²ç”¨æ–¼æ¼”ç¤ºï¼‰\n",
    "batch_results = batch_brand_analysis(sample_texts, batch_size=3, delay=0.5)\n",
    "\n",
    "# åˆ†æçµæœ\n",
    "print(\"\\nğŸ“Š æ‰¹é‡åˆ†æçµæœçµ±è¨ˆï¼š\")\n",
    "total_brands = []\n",
    "for result in batch_results:\n",
    "    total_brands.extend(result['brands'])\n",
    "\n",
    "from collections import Counter\n",
    "brand_counts = Counter(total_brands)\n",
    "\n",
    "print(f\"ğŸª ç¸½å…±è­˜åˆ¥å‡º {len(set(total_brands))} å€‹ä¸åŒå“ç‰Œ\")\n",
    "print(f\"ğŸ“ˆ å“ç‰Œçµ±è¨ˆï¼š{dict(brand_counts)}\")\n",
    "print(f\"âœ… æˆåŠŸç‡ï¼š{len([r for r in batch_results if r['brands']]) / len(batch_results) * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
