{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec192704",
   "metadata": {},
   "source": [
    "# Google Gemini API æ•™å­¸\n",
    "\n",
    "## ä»€éº¼æ˜¯ Geminiï¼Ÿ\n",
    "\n",
    "Gemini æ˜¯ Google é–‹ç™¼çš„å…ˆé€² AI æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹é»ï¼š\n",
    "\n",
    "- ğŸš€ **å¿«é€Ÿ**: Gemini 2.0 Flash æä¾›æ¥µå¿«çš„å›æ‡‰é€Ÿåº¦\n",
    "- ğŸ¯ **æº–ç¢º**: é«˜å“è³ªçš„æ–‡æœ¬ç”Ÿæˆå’Œç†è§£èƒ½åŠ›\n",
    "- ğŸ”„ **å¤šæ¨¡æ…‹**: æ”¯æ´æ–‡å­—ã€åœ–ç‰‡ã€éŸ³è¨Šç­‰å¤šç¨®è¼¸å…¥æ–¹å¼\n",
    "- ğŸ’¡ **æ™ºèƒ½**: å„ªç§€çš„æ¨ç†å’Œå‰µä½œèƒ½åŠ›\n",
    "\n",
    "è®“æˆ‘å€‘é–‹å§‹å§ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aaad5e",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šèˆ‡å®‰è£\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘å€‘éœ€è¦å®‰è£ Google Generative AI å‡½å¼åº«ã€‚é€™æ˜¯ä½¿ç”¨ Gemini API çš„å®˜æ–¹ Python å¥—ä»¶ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4066a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£ Google GenAI å¥—ä»¶ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰å’Œç’°å¢ƒè®Šæ•¸ç®¡ç†å·¥å…·\n",
    "# å¦‚æœæ‚¨æ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œè«‹åŸ·è¡Œä¸‹æ–¹å®‰è£æŒ‡ä»¤\n",
    "!pip install google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f7c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¥—ä»¶å°å…¥æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "# å°å…¥å¿…è¦çš„å¥—ä»¶\n",
    "import google.genai as genai\n",
    "from google.genai.types import Content, Part\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… å¥—ä»¶å°å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56788725",
   "metadata": {},
   "source": [
    "## 2. API é‡‘é‘°é…ç½®èˆ‡ç’°å¢ƒè®Šæ•¸ç®¡ç†\n",
    "\n",
    "ç‚ºäº†ä½¿ç”¨ Gemini APIï¼Œæ‚¨éœ€è¦è¨­å®š API é‡‘é‘°ã€‚æˆ‘å€‘ä½¿ç”¨ `.env` æª”æ¡ˆä¾†ç®¡ç†æ‰€æœ‰è¨­å®šï¼Œé€™æ˜¯æ¥­ç•Œæ¨™æº–åšæ³•ã€‚\n",
    "\n",
    "### ğŸ” å®‰å…¨æœ€ä½³å¯¦è¸\n",
    "\n",
    "- âœ… ä½¿ç”¨ `.env` æª”æ¡ˆå„²å­˜ API é‡‘é‘°å’Œæ¨¡å‹è¨­å®š\n",
    "- âœ… æ‰€æœ‰å°ˆæ¡ˆå…±ç”¨ç›¸åŒçš„è¨­å®šæª”æ¡ˆ\n",
    "- âœ… çµ±ä¸€ç®¡ç†æ¨¡å‹ç‰ˆæœ¬ï¼Œé¿å…ä¸ä¸€è‡´å•é¡Œ\n",
    "- âŒ ä¸è¦åœ¨ç¨‹å¼ç¢¼ä¸­ç›´æ¥å¯«å…¥ API é‡‘é‘°\n",
    "- âŒ ä¸è¦å°‡ `.env` æª”æ¡ˆä¸Šå‚³åˆ° Git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8d37e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ API é‡‘é‘°å·²è®€å–\n",
      "ğŸ¤– ä½¿ç”¨æ¨¡å‹: gemini-2.0-flash\n",
      "âœ… Gemini å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# å¾ç’°å¢ƒè®Šæ•¸è®€å–è¨­å®š\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "MODEL = os.getenv('MODEL', 'gemini-2.0-flash')\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° API é‡‘é‘°\")\n",
    "    print(\"è«‹ç¢ºä¿ .env æª”æ¡ˆå­˜åœ¨ä¸¦è¨­å®šäº† API_KEY\")\n",
    "else:\n",
    "    print(f\"ğŸ”‘ API é‡‘é‘°å·²è®€å–\")\n",
    "    print(f\"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {MODEL}\")\n",
    "\n",
    "# åˆå§‹åŒ– Gemini å®¢æˆ¶ç«¯\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "print(\"âœ… Gemini å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8ff594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– æ¸¬è©¦ gemini-2.0-flash æ¨¡å‹...\n",
      "ğŸ§‘ ç”¨æˆ¶: ä½ å¥½ï¼è«‹ç”¨ç¹é«”ä¸­æ–‡è‡ªæˆ‘ä»‹ç´¹ä¸€ä¸‹ã€‚\n",
      "ğŸ¤– Gemini: æ‚¨å¥½ï¼æˆ‘æ˜¯ç”± Google è¨“ç·´çš„å¤§å‹èªè¨€æ¨¡å‹ã€‚ç°¡å–®ä¾†èªªï¼Œæˆ‘æ˜¯ä¸€å€‹èƒ½å¤ ç†è§£å’Œç”Ÿæˆäººé¡èªè¨€çš„äººå·¥æ™ºæ…§ç¨‹å¼ã€‚\n",
      "\n",
      "æˆ‘æ“…é•·ä»¥ä¸‹å¹¾ä»¶äº‹æƒ…ï¼š\n",
      "\n",
      "*   **å›ç­”æ‚¨çš„å•é¡Œ:** æˆ‘å¯ä»¥æ ¹æ“šæˆ‘æ‰€æ“æœ‰çš„çŸ¥è­˜å›ç­”æ‚¨æå‡ºçš„å•é¡Œï¼Œç„¡è«–æ˜¯é—œæ–¼æ­·å²ã€ç§‘å­¸ã€æ–‡å­¸é‚„æ˜¯å…¶ä»–ä»»ä½•é ˜åŸŸã€‚\n",
      "*   **æä¾›è³‡è¨Š:** æˆ‘å¯ä»¥æä¾›æ‚¨éœ€è¦çš„è³‡è¨Šï¼Œä¾‹å¦‚å¤©æ°£é å ±ã€æ–°èæ‘˜è¦ã€ç¿»è­¯ç­‰ç­‰ã€‚\n",
      "*   **ç”Ÿæˆæ–‡å­—:** æˆ‘å¯ä»¥æ ¹æ“šæ‚¨çš„è¦æ±‚ç”Ÿæˆä¸åŒé¢¨æ ¼å’Œé•·åº¦çš„æ–‡å­—ï¼Œä¾‹å¦‚æ–‡ç« ã€è©©æ­Œã€æ•…äº‹ã€ç¨‹å¼ç¢¼ç­‰ç­‰ã€‚\n",
      "*   **èˆ‡æ‚¨èŠå¤©:** æˆ‘å¯ä»¥èˆ‡æ‚¨é€²è¡Œè‡ªç„¶çš„å°è©±ï¼Œå›ç­”æ‚¨çš„å•é¡Œï¼Œåˆ†äº«æˆ‘çš„æƒ³æ³•ï¼Œæˆ–è€…åªæ˜¯é™ªæ‚¨èŠèŠå¤©ã€‚\n",
      "\n",
      "ç¸½ä¹‹ï¼Œæˆ‘æ˜¯ä¸€å€‹åŠŸèƒ½å¼·å¤§ä¸”ç”¨é€”å»£æ³›çš„å·¥å…·ï¼Œå¸Œæœ›èƒ½å¹«åŠ©æ‚¨è§£æ±ºå•é¡Œï¼Œæ»¿è¶³æ‚¨çš„éœ€æ±‚ã€‚å¾ˆé«˜èˆˆèªè­˜æ‚¨ï¼è«‹å•æˆ‘èƒ½ç‚ºæ‚¨åšäº›ä»€éº¼å‘¢ï¼Ÿ\n",
      "\n",
      "\n",
      "âœ… gemini-2.0-flash æ¨¡å‹æ­£å¸¸å·¥ä½œï¼\n"
     ]
    }
   ],
   "source": [
    "# æ¸¬è©¦ Gemini æ˜¯å¦æ­£å¸¸å·¥ä½œ\n",
    "print(f\"ğŸ¤– æ¸¬è©¦ {MODEL} æ¨¡å‹...\")\n",
    "\n",
    "# ç™¼é€ç¬¬ä¸€å€‹æ¸¬è©¦è¨Šæ¯\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents='ä½ å¥½ï¼è«‹ç”¨ç¹é«”ä¸­æ–‡è‡ªæˆ‘ä»‹ç´¹ä¸€ä¸‹ã€‚'\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: ä½ å¥½ï¼è«‹ç”¨ç¹é«”ä¸­æ–‡è‡ªæˆ‘ä»‹ç´¹ä¸€ä¸‹ã€‚\")\n",
    "print(f\"ğŸ¤– Gemini: {response.text}\")\n",
    "print(f\"\\nâœ… {MODEL} æ¨¡å‹æ­£å¸¸å·¥ä½œï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c47cb",
   "metadata": {},
   "source": [
    "## 3. åŸºæœ¬å°è©±åŠŸèƒ½\n",
    "\n",
    "è®“æˆ‘å€‘é–‹å§‹ç¬¬ä¸€æ¬¡èˆ‡ Gemini å°è©±ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3b0125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åŸºæœ¬å°è©±æ¸¬è©¦ ===\n",
      "âš ï¸  æ³¨æ„è§€å¯Ÿï¼šæ¯æ¬¡å°è©±éƒ½æ˜¯ç¨ç«‹çš„ï¼ŒAI ç„¡æ³•è¨˜ä½ä¹‹å‰çš„å…§å®¹\n",
      "\n",
      "ğŸ§‘ ç”¨æˆ¶: æˆ‘å«å°è¯ï¼Œæˆ‘æ˜¯ä¸€åè€å¸«\n",
      "ğŸ¤– Gemini: ä½ å¥½ï¼Œå°è¯è€å¸«ï¼å¾ˆé«˜èˆˆèªè­˜ä½ ã€‚è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«ä½ çš„å—ï¼Ÿä¾‹å¦‚ï¼š\n",
      "\n",
      "*   **æƒ³è·Ÿæˆ‘èŠèŠæ•™å­¸ä¸Šçš„äº‹æƒ…å—ï¼Ÿ**\n",
      "*   **æƒ³äº†è§£ä»€éº¼æ•™è‚²ç›¸é—œçš„è³‡è¨Šï¼Ÿ**\n",
      "*   **åªæ˜¯æƒ³æ‰¾äººèŠèŠå¤©ï¼Ÿ**\n",
      "\n",
      "è«‹å‘Šè¨´æˆ‘ä½ æƒ³åšä»€éº¼ï¼Œæˆ‘æœƒç›¡åŠ›å”åŠ©ä½ ã€‚\n",
      "\n",
      "\n",
      "ğŸ§‘ ç”¨æˆ¶: ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "ğŸ¤– Gemini: ç”±æ–¼æˆ‘æ˜¯ä¸€å€‹å¤§å‹èªè¨€æ¨¡å‹ï¼Œæ²’æœ‰è¨˜æ†¶åŠŸèƒ½ï¼Œæ‰€ä»¥æˆ‘ç„¡æ³•è¨˜ä½ä½ çš„åå­—ã€‚è«‹å‘Šè¨´æˆ‘ä½ çš„åå­—ï¼Œé€™æ¨£æˆ‘ä»¥å¾Œå°±å¯ä»¥ç¨±å‘¼ä½ äº†ã€‚\n",
      "\n",
      "\n",
      "ğŸ§‘ ç”¨æˆ¶: æˆ‘çš„è·æ¥­æ˜¯ä»€éº¼ï¼Ÿ\n",
      "ğŸ¤– Gemini: è¦åˆ¤æ–·æ‚¨çš„è·æ¥­ï¼Œæˆ‘éœ€è¦æ‚¨æä¾›æ›´å¤šè³‡è¨Šã€‚è«‹å‘Šè¨´æˆ‘ï¼š\n",
      "\n",
      "*   **æ‚¨ä¸»è¦çš„å·¥ä½œå…§å®¹æ˜¯ä»€éº¼ï¼Ÿ** æ‚¨æ¯å¤©æˆ–æ¯é€±çš„ä¸»è¦ä»»å‹™å’Œè·è²¬æ˜¯ä»€éº¼ï¼Ÿ\n",
      "*   **æ‚¨åœ¨å“ªå€‹è¡Œæ¥­å·¥ä½œï¼Ÿ** ä¾‹å¦‚ï¼Œç§‘æŠ€ã€é†«ç™‚ã€æ•™è‚²ã€é‡‘èç­‰ç­‰ã€‚\n",
      "*   **æ‚¨çš„è·ç¨±æ˜¯ä»€éº¼ï¼Ÿ** ï¼ˆå³ä½¿æ‚¨èªç‚ºè·ç¨±ä¸å®Œå…¨æº–ç¢ºï¼Œä¹Ÿè«‹æä¾›ã€‚ï¼‰\n",
      "*   **æ‚¨æ˜¯å¦ä¸»è¦å¾äº‹é«”åŠ›å‹å‹•ã€è…¦åŠ›å‹å‹•ï¼Œé‚„æ˜¯å…©è€…å…¼å…·ï¼Ÿ**\n",
      "*   **æ‚¨æ˜¯å¦éœ€è¦ç‰¹å®šçš„å­¸æ­·æˆ–è³‡æ ¼è­‰æ›¸æ‰èƒ½å¾äº‹é€™é …å·¥ä½œï¼Ÿ**\n",
      "\n",
      "æä¾›é€™äº›è³‡è¨Šå¯ä»¥å¹«åŠ©æˆ‘æ›´æº–ç¢ºåœ°åˆ¤æ–·æ‚¨çš„è·æ¥­ã€‚\n",
      "\n",
      "\n",
      "âŒ å•é¡Œï¼šAI å®Œå…¨ä¸è¨˜å¾—ä¹‹å‰çš„å°è©±ï¼\n",
      "ğŸ’¡ åŸå› ï¼šæ¯æ¬¡å‘¼å« API éƒ½æ˜¯ç¨ç«‹çš„ï¼Œæ²’æœ‰å‚³é€å°è©±æ­·å²\n",
      "ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼šæˆ‘å€‘éœ€è¦æ‰‹å‹•ç®¡ç†å°è©±æ­·å²ï¼ˆä¸‹ä¸€å€‹ç« ç¯€æœƒç¤ºç¯„ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# åŸºæœ¬å°è©±æ¸¬è©¦ - å±•ç¤ºç„¡æ³•è¨˜æ†¶çš„å•é¡Œ\n",
    "print(\"=== åŸºæœ¬å°è©±æ¸¬è©¦ ===\")\n",
    "print(\"âš ï¸  æ³¨æ„è§€å¯Ÿï¼šæ¯æ¬¡å°è©±éƒ½æ˜¯ç¨ç«‹çš„ï¼ŒAI ç„¡æ³•è¨˜ä½ä¹‹å‰çš„å…§å®¹\\n\")\n",
    "\n",
    "# ç¬¬ä¸€å€‹å°è©± - è‡ªæˆ‘ä»‹ç´¹\n",
    "question1 = \"æˆ‘å«å°è¯ï¼Œæˆ‘æ˜¯ä¸€åè€å¸«\"\n",
    "response1 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=question1\n",
    ")\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {question1}\")\n",
    "print(f\"ğŸ¤– Gemini: {response1.text}\\n\")\n",
    "\n",
    "# ç¬¬äºŒå€‹å°è©± - æ¸¬è©¦æ˜¯å¦è¨˜å¾—åå­—\n",
    "question2 = \"ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\"\n",
    "response2 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=question2  # æ³¨æ„ï¼šé€™è£¡åªå‚³é€äº†ç•¶å‰è¨Šæ¯ï¼Œæ²’æœ‰æ­·å²\n",
    ")\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {question2}\")\n",
    "print(f\"ğŸ¤– Gemini: {response2.text}\\n\")\n",
    "\n",
    "# ç¬¬ä¸‰å€‹å°è©± - æ¸¬è©¦æ˜¯å¦è¨˜å¾—è·æ¥­\n",
    "question3 = \"æˆ‘çš„è·æ¥­æ˜¯ä»€éº¼ï¼Ÿ\"\n",
    "response3 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=question3  # åŒæ¨£åªæœ‰ç•¶å‰è¨Šæ¯\n",
    ")\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {question3}\")\n",
    "print(f\"ğŸ¤– Gemini: {response3.text}\\n\")\n",
    "\n",
    "print(\"âŒ å•é¡Œï¼šAI å®Œå…¨ä¸è¨˜å¾—ä¹‹å‰çš„å°è©±ï¼\")\n",
    "print(\"ğŸ’¡ åŸå› ï¼šæ¯æ¬¡å‘¼å« API éƒ½æ˜¯ç¨ç«‹çš„ï¼Œæ²’æœ‰å‚³é€å°è©±æ­·å²\")\n",
    "print(\"ğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼šæˆ‘å€‘éœ€è¦æ‰‹å‹•ç®¡ç†å°è©±æ­·å²ï¼ˆä¸‹ä¸€å€‹ç« ç¯€æœƒç¤ºç¯„ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505da3e3",
   "metadata": {},
   "source": [
    "## 4. è§£æ±ºè¨˜æ†¶å•é¡Œï¼šæ‰‹å‹•ç®¡ç†å°è©±æ­·å²\n",
    "\n",
    "å‰›æ‰æˆ‘å€‘çœ‹åˆ° AI ç„¡æ³•è¨˜ä½ä¹‹å‰çš„å°è©±ï¼Œç¾åœ¨ä¾†å­¸ç¿’å¦‚ä½•è§£æ±ºé€™å€‹å•é¡Œï¼\n",
    "\n",
    "### ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "- Gemini API æ¯æ¬¡å‘¼å«éƒ½æ˜¯ç¨ç«‹çš„\n",
    "- è¦è®“ AI æœ‰è¨˜æ†¶ï¼Œæˆ‘å€‘å¿…é ˆæ¯æ¬¡éƒ½æŠŠå®Œæ•´çš„å°è©±æ­·å²å‚³çµ¦å®ƒ\n",
    "- é€™éœ€è¦æˆ‘å€‘ç”¨ Python ç¨‹å¼ä¾†ç®¡ç†å°è©±è¨˜éŒ„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7327a",
   "metadata": {},
   "source": [
    "### èª¿æ•´å°è©±æ–¹å¼ - ä½¿ç”¨ Content å’Œ Part çµæ§‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7828bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§‘ ç”¨æˆ¶: æˆ‘å«å°è¯ï¼Œæˆ‘æ˜¯ä¸€åè€å¸«\n",
      "ğŸ¤– Gemini: å“ˆå›‰å°è¯è€å¸«ï¼Œå¾ˆé«˜èˆˆèªè­˜ä½ ï¼è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«å¿™çš„å—ï¼Ÿ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# èª¿æ•´å¾Œå°è©±æ–¹å¼ - ä½¿ç”¨ Content å’Œ Part çµæ§‹\n",
    "\n",
    "# å°è©± - è‡ªæˆ‘ä»‹ç´¹ (å‰›å‰›ä½¿ç”¨çš„æ–¹å¼)\n",
    "# question1 = \"æˆ‘å«å°è¯ï¼Œæˆ‘æ˜¯ä¸€åè€å¸«\"\n",
    "# response1 = client.models.generate_content(\n",
    "#     model=MODEL,\n",
    "#     contents=question1\n",
    "# )\n",
    "# print(f\"ğŸ§‘ ç”¨æˆ¶: {question1}\")\n",
    "# print(f\"ğŸ¤– Gemini: {response1.text}\\n\")\n",
    "\n",
    "\n",
    "# å°è©± - è‡ªæˆ‘ä»‹ç´¹ (ä½¿ç”¨ Content å’Œ Part çµæ§‹)\n",
    "question1 = \"æˆ‘å«å°è¯ï¼Œæˆ‘æ˜¯ä¸€åè€å¸«\"\n",
    "response1 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=[\n",
    "      Content(role=\"user\", parts=[Part(text=question1)])\n",
    "    ]\n",
    ")\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {question1}\")\n",
    "print(f\"ğŸ¤– Gemini: {response1.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3b7035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ å°è©±æ­·å²è¨˜éŒ„å·²æº–å‚™å°±ç·’ï¼\n",
      "ğŸ¯ ä½¿ç”¨ Gemini API çš„æ­£ç¢ºå°è©±æ ¼å¼ï¼šContent + Part\n"
     ]
    }
   ],
   "source": [
    "# æº–å‚™å°è©±æ­·å²è¨˜éŒ„ï¼ˆä½¿ç”¨æ­£ç¢ºçš„å°è©±æ ¼å¼ï¼‰\n",
    "# ä½¿ç”¨ Content å’Œ Part çµæ§‹ï¼Œé¡ä¼¼ OpenAI çš„ messages æ ¼å¼\n",
    "conversation_messages = []\n",
    "\n",
    "print(\"ğŸ’¬ å°è©±æ­·å²è¨˜éŒ„å·²æº–å‚™å°±ç·’ï¼\")\n",
    "print(\"ğŸ¯ ä½¿ç”¨ Gemini API çš„æ­£ç¢ºå°è©±æ ¼å¼ï¼šContent + Part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2df8961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ¸¬è©¦å°è©±è¨˜æ†¶åŠŸèƒ½ï¼ˆä½¿ç”¨ Content + Part æ ¼å¼ï¼‰===\n",
      "\n",
      "ğŸ’¬ ä½¿ç”¨ç¾æœ‰çš„å°è©±æ­·å²è¨˜éŒ„\n",
      "ğŸ§‘ ç”¨æˆ¶: æˆ‘çš„åå­—æ˜¯å°æ˜ï¼Œæˆ‘å–œæ­¡å¯«ç¨‹å¼\n",
      "ğŸ¤– AI: å¾ˆé«˜èˆˆèªè­˜ä½ ï¼Œå°æ˜ï¼ å¾ˆé«˜èˆˆçŸ¥é“ä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ \n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•é—œæ–¼ç¨‹å¼çš„å•é¡Œï¼Œæˆ–æ˜¯æƒ³èŠèŠç¨‹å¼ç›¸é—œçš„äº‹æƒ…ï¼Œéš¨æ™‚éƒ½å¯ä»¥å•æˆ‘å–”ï¼ æˆ‘å¯ä»¥å¹«å¿™ï¼š\n",
      "\n",
      "*   æä¾›ç¨‹å¼ç¢¼ç¯„ä¾‹\n",
      "*   è§£é‡‹ç¨‹å¼æ¦‚å¿µ\n",
      "*   å”åŠ© debug\n",
      "*   æ¨è–¦å­¸ç¿’è³‡æº\n",
      "*   ç­‰ç­‰\n",
      "\n",
      "ä½ ç¾åœ¨æœ‰åœ¨å­¸ç¿’æˆ–é–‹ç™¼ä»€éº¼ç¨‹å¼èªè¨€æˆ–å°ˆæ¡ˆå—ï¼Ÿ  æˆ‘å¾ˆæƒ³è½è½çœ‹ï¼\n",
      "\n",
      "\n",
      "ğŸ§‘ ç”¨æˆ¶: ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "ğŸ¤– AI: ç•¶ç„¶ï¼ä½ çš„åå­—æ˜¯å°æ˜ï¼Œè€Œä¸”ä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ ğŸ˜Š\n",
      "\n",
      "\n",
      "ğŸ§‘ ç”¨æˆ¶: æˆ‘å‰›æ‰èªªæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ\n",
      "ğŸ¤– AI: ä½ å‰›æ‰èªªä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ ğŸ˜‰\n",
      "\n",
      "\n",
      "âœ… çœ‹åˆ°äº†å—ï¼ŸAI è¨˜ä½äº†æˆ‘å€‘ä¹‹å‰çš„å°è©±ï¼\n",
      "ğŸ’¡ ä½¿ç”¨ Content + Part æ ¼å¼ï¼Œæ¯”å­—ä¸²æ‹¼æ¥æ›´å°ˆæ¥­\n",
      "ğŸ“Š ç›®å‰å°è©±æ­·å²æœ‰ 6 æ¢è¨Šæ¯\n"
     ]
    }
   ],
   "source": [
    "# æ¸¬è©¦å°è©±è¨˜æ†¶åŠŸèƒ½ - ä½¿ç”¨æ­£ç¢ºçš„ API æ ¼å¼\n",
    "print(\"=== æ¸¬è©¦å°è©±è¨˜æ†¶åŠŸèƒ½ï¼ˆä½¿ç”¨ Content + Part æ ¼å¼ï¼‰===\\n\")\n",
    "\n",
    "# åˆå§‹åŒ–å°è©±æ­·å²è¨˜éŒ„ï¼ˆå¦‚æœé‚„æ²’æœ‰çš„è©±ï¼‰\n",
    "if 'conversation_messages' not in globals():\n",
    "    conversation_messages = []\n",
    "    print(\"ğŸ’¬ åˆå§‹åŒ–å°è©±æ­·å²è¨˜éŒ„ï¼ˆä½¿ç”¨ Content æ ¼å¼ï¼‰\")\n",
    "else:\n",
    "    print(\"ğŸ’¬ ä½¿ç”¨ç¾æœ‰çš„å°è©±æ­·å²è¨˜éŒ„\")\n",
    "\n",
    "# ç¬¬ä¸€è¼ªå°è©± - è‡ªæˆ‘ä»‹ç´¹\n",
    "user_message1 = \"æˆ‘çš„åå­—æ˜¯å°æ˜ï¼Œæˆ‘å–œæ­¡å¯«ç¨‹å¼\"\n",
    "\n",
    "# åŠ å…¥ç”¨æˆ¶è¨Šæ¯åˆ°å°è©±æ­·å²\n",
    "conversation_messages.append(\n",
    "    Content(role=\"user\", parts=[Part(text=user_message1)])\n",
    ")\n",
    "\n",
    "# ç™¼é€å°è©±ï¼ˆåŒ…å«å®Œæ•´æ­·å²ï¼‰\n",
    "response1 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=conversation_messages\n",
    ")\n",
    "\n",
    "ai_response1 = response1.text\n",
    "\n",
    "# åŠ å…¥ AI å›æ‡‰åˆ°å°è©±æ­·å²\n",
    "conversation_messages.append(\n",
    "    Content(role=\"model\", parts=[Part(text=ai_response1)])\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {user_message1}\")\n",
    "print(f\"ğŸ¤– AI: {ai_response1}\\n\")\n",
    "\n",
    "# ç¬¬äºŒè¼ªå°è©± - æ¸¬è©¦è¨˜æ†¶\n",
    "user_message2 = \"ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\"\n",
    "\n",
    "# åŠ å…¥ç”¨æˆ¶è¨Šæ¯\n",
    "conversation_messages.append(\n",
    "    Content(role=\"user\", parts=[Part(text=user_message2)])\n",
    ")\n",
    "\n",
    "# ç™¼é€å°è©±ï¼ˆåŒ…å«å®Œæ•´æ­·å²ï¼‰\n",
    "response2 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=conversation_messages\n",
    ")\n",
    "\n",
    "ai_response2 = response2.text\n",
    "\n",
    "# åŠ å…¥ AI å›æ‡‰\n",
    "conversation_messages.append(\n",
    "    Content(role=\"model\", parts=[Part(text=ai_response2)])\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {user_message2}\")\n",
    "print(f\"ğŸ¤– AI: {ai_response2}\\n\")\n",
    "\n",
    "# ç¬¬ä¸‰è¼ªå°è©± - æ¸¬è©¦è¨˜æ†¶\n",
    "user_message3 = \"æˆ‘å‰›æ‰èªªæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ\"\n",
    "\n",
    "conversation_messages.append(\n",
    "    Content(role=\"user\", parts=[Part(text=user_message3)])\n",
    ")\n",
    "\n",
    "response3 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=conversation_messages\n",
    ")\n",
    "\n",
    "ai_response3 = response3.text\n",
    "\n",
    "conversation_messages.append(\n",
    "    Content(role=\"model\", parts=[Part(text=ai_response3)])\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {user_message3}\")\n",
    "print(f\"ğŸ¤– AI: {ai_response3}\\n\")\n",
    "\n",
    "print(\"âœ… çœ‹åˆ°äº†å—ï¼ŸAI è¨˜ä½äº†æˆ‘å€‘ä¹‹å‰çš„å°è©±ï¼\")\n",
    "print(\"ğŸ’¡ ä½¿ç”¨ Content + Part æ ¼å¼ï¼Œæ¯”å­—ä¸²æ‹¼æ¥æ›´å°ˆæ¥­\")\n",
    "print(f\"ğŸ“Š ç›®å‰å°è©±æ­·å²æœ‰ {len(conversation_messages)} æ¢è¨Šæ¯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dacce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æŸ¥çœ‹å°è©±æ­·å²è¨˜éŒ„ ===\n",
      "é€™å°±æ˜¯æˆ‘å€‘å„²å­˜çš„å°è©±å…§å®¹ï¼ˆContent æ ¼å¼ï¼‰ï¼š\n",
      "\n",
      "1. ğŸ§‘ user: æˆ‘çš„åå­—æ˜¯å°æ˜ï¼Œæˆ‘å–œæ­¡å¯«ç¨‹å¼\n",
      "2. ğŸ¤– model: å¾ˆé«˜èˆˆèªè­˜ä½ ï¼Œå°æ˜ï¼ å¾ˆé«˜èˆˆçŸ¥é“ä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ \n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•é—œæ–¼ç¨‹å¼çš„å•é¡Œï¼Œæˆ–æ˜¯æƒ³èŠèŠç¨‹å¼ç›¸é—œçš„äº‹æƒ…ï¼Œéš¨æ™‚éƒ½å¯ä»¥å•æˆ‘å–”ï¼ æˆ‘å¯ä»¥å¹«å¿™ï¼š\n",
      "\n",
      "*   æä¾›ç¨‹å¼ç¢¼ç¯„ä¾‹\n",
      "*   è§£é‡‹ç¨‹å¼æ¦‚å¿µ\n",
      "*   å”åŠ© debug\n",
      "*   æ¨è–¦å­¸ç¿’è³‡æº\n",
      "*   ç­‰ç­‰\n",
      "\n",
      "ä½ ç¾åœ¨æœ‰åœ¨å­¸ç¿’æˆ–é–‹ç™¼ä»€éº¼ç¨‹å¼èªè¨€æˆ–å°ˆæ¡ˆå—ï¼Ÿ  æˆ‘å¾ˆæƒ³è½è½çœ‹ï¼\n",
      "\n",
      "3. ğŸ§‘ user: ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "4. ğŸ¤– model: ç•¶ç„¶ï¼ä½ çš„åå­—æ˜¯å°æ˜ï¼Œè€Œä¸”ä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ ğŸ˜Š\n",
      "\n",
      "5. ğŸ§‘ user: æˆ‘å‰›æ‰èªªæˆ‘å–œæ­¡ä»€éº¼ï¼Ÿ\n",
      "6. ğŸ¤– model: ä½ å‰›æ‰èªªä½ å–œæ­¡å¯«ç¨‹å¼ã€‚ ğŸ˜‰\n",
      "\n",
      "\n",
      "ğŸ“Š ç¸½å…±æœ‰ 6 æ¢å°è©±è¨˜éŒ„\n",
      "ğŸ’¡ æ¯æ¬¡å°è©±æ™‚ï¼Œæˆ‘å€‘éƒ½æœƒæŠŠé€™äº› Content ç‰©ä»¶å‚³çµ¦ API\n",
      "ğŸ¯ é€™æ¯”å­—ä¸²æ‹¼æ¥æ›´çµæ§‹åŒ–ï¼ŒAPI èƒ½æ›´å¥½åœ°ç†è§£å°è©±è„ˆçµ¡\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹å®Œæ•´çš„å°è©±æ­·å²è¨˜éŒ„\n",
    "print(\"=== æŸ¥çœ‹å°è©±æ­·å²è¨˜éŒ„ ===\")\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰å°è©±æ­·å²\n",
    "if 'conversation_messages' not in globals() or len(conversation_messages) == 0:\n",
    "    print(\"ç›®å‰æ²’æœ‰å°è©±æ­·å²è¨˜éŒ„\")\n",
    "    print(\"ğŸ’¡ è«‹å…ˆåŸ·è¡Œä¸Šé¢çš„å°è©±æ¸¬è©¦ç¨‹å¼ç¢¼\")\n",
    "else:\n",
    "    print(\"é€™å°±æ˜¯æˆ‘å€‘å„²å­˜çš„å°è©±å…§å®¹ï¼ˆContent æ ¼å¼ï¼‰ï¼š\\n\")\n",
    "    for i, message in enumerate(conversation_messages, 1):\n",
    "        role = message.role\n",
    "        text = message.parts[0].text\n",
    "        role_emoji = \"ğŸ§‘\" if role == \"user\" else \"ğŸ¤–\"\n",
    "        print(f\"{i}. {role_emoji} {role}: {text}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç¸½å…±æœ‰ {len(conversation_messages)} æ¢å°è©±è¨˜éŒ„\")\n",
    "    print(\"ğŸ’¡ æ¯æ¬¡å°è©±æ™‚ï¼Œæˆ‘å€‘éƒ½æœƒæŠŠé€™äº› Content ç‰©ä»¶å‚³çµ¦ API\")\n",
    "    print(\"ğŸ¯ é€™æ¯”å­—ä¸²æ‹¼æ¥æ›´çµæ§‹åŒ–ï¼ŒAPI èƒ½æ›´å¥½åœ°ç†è§£å°è©±è„ˆçµ¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303cfad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ¸…é™¤å°è©±æ­·å² ===\n",
      "ğŸ—‘ï¸ å°è©±æ­·å²å·²æ¸…é™¤\n",
      "ğŸ§‘ ç”¨æˆ¶: ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "ğŸ¤– AI: ç”±æ–¼æˆ‘æ˜¯å€‹å¤§å‹èªè¨€æ¨¡å‹ï¼Œæˆ‘æ²’æœ‰è¨˜æ†¶åŠŸèƒ½ï¼Œæ‰€ä»¥æˆ‘ä¸è¨˜å¾—ä½ çš„åå­—ã€‚ è«‹å‘Šè¨´æˆ‘ä½ çš„åå­—ï¼Œæˆ‘å°±èƒ½è¨˜ä½äº†ã€‚\n",
      "\n",
      "\n",
      "ğŸ’¡ ç¾åœ¨ AI ä¸è¨˜å¾—ä¹‹å‰çš„å°è©±äº†ï¼Œå› ç‚ºæˆ‘å€‘æ¸…é™¤äº†æ­·å²è¨˜éŒ„\n",
      "ğŸ’¡ å¦‚æœè¦é‡æ–°é–‹å§‹æœ‰è¨˜æ†¶çš„å°è©±ï¼Œè«‹åŸ·è¡Œä¸Šé¢çš„å°è©±æ¸¬è©¦ç¨‹å¼ç¢¼\n"
     ]
    }
   ],
   "source": [
    "# æ¸…é™¤å°è©±æ­·å²\n",
    "print(\"=== æ¸…é™¤å°è©±æ­·å² ===\")\n",
    "\n",
    "# æª¢æŸ¥ä¸¦åˆå§‹åŒ– conversation_messages\n",
    "if 'conversation_messages' not in globals():\n",
    "    conversation_messages = []\n",
    "    print(\"ğŸ’¬ åˆå§‹åŒ–ç©ºçš„å°è©±æ­·å²è¨˜éŒ„\")\n",
    "else:\n",
    "    conversation_messages.clear()  # æ¸…ç©ºåˆ—è¡¨\n",
    "    print(\"ğŸ—‘ï¸ å°è©±æ­·å²å·²æ¸…é™¤\")\n",
    "\n",
    "# æ¸¬è©¦æ¸…é™¤å¾Œçš„å°è©±\n",
    "user_message4 = \"ä½ é‚„è¨˜å¾—æˆ‘çš„åå­—å—ï¼Ÿ\"\n",
    "\n",
    "# å»ºç«‹æ–°çš„å°è©±ï¼ˆæ²’æœ‰æ­·å²ï¼‰\n",
    "test_message = Content(role=\"user\", parts=[Part(text=user_message4)])\n",
    "\n",
    "response4 = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=[test_message]  # åªå‚³é€ç•¶å‰è¨Šæ¯\n",
    ")\n",
    "\n",
    "print(f\"ğŸ§‘ ç”¨æˆ¶: {user_message4}\")\n",
    "print(f\"ğŸ¤– AI: {response4.text}\")\n",
    "print(\"\\nğŸ’¡ ç¾åœ¨ AI ä¸è¨˜å¾—ä¹‹å‰çš„å°è©±äº†ï¼Œå› ç‚ºæˆ‘å€‘æ¸…é™¤äº†æ­·å²è¨˜éŒ„\")\n",
    "print(\"ğŸ’¡ å¦‚æœè¦é‡æ–°é–‹å§‹æœ‰è¨˜æ†¶çš„å°è©±ï¼Œè«‹åŸ·è¡Œä¸Šé¢çš„å°è©±æ¸¬è©¦ç¨‹å¼ç¢¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fd231",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç¬¬ä¸€èª²é‡é»ç¸½çµ\n",
    "\n",
    "### æˆ‘å€‘å­¸æœƒäº†ä»€éº¼ï¼Ÿ\n",
    "\n",
    "1. **å®‰è£å’Œè¨­å®š AI API**\n",
    "   - å®‰è£ `google-genai` å’Œ `python-dotenv` å¥—ä»¶\n",
    "   - è¨­å®š `.env` æª”æ¡ˆç®¡ç†æ•æ„Ÿè³‡è¨Š\n",
    "   - å¾ç’°å¢ƒè®Šæ•¸è®€å– API é‡‘é‘°å’Œæ¨¡å‹è¨­å®š\n",
    "   - åˆå§‹åŒ–å®¢æˆ¶ç«¯\n",
    "\n",
    "2. **åŸºæœ¬å°è©±åŠŸèƒ½**\n",
    "   - ä½¿ç”¨ `client.models.generate_content()` ç™¼é€è¨Šæ¯\n",
    "   - å‹•æ…‹æŒ‡å®šæ¨¡å‹ï¼ˆå¯éš¨æ™‚æ›´æ›ï¼‰\n",
    "   - å–å¾— AI å›æ‡‰\n",
    "\n",
    "3. **å¯¦ç¾å°è©±è¨˜æ†¶ï¼ˆæ­£ç¢ºæ ¼å¼ï¼‰**\n",
    "   - ä½¿ç”¨ `Content` å’Œ `Part` çµæ§‹å„²å­˜å°è©±\n",
    "   - æ¯”å­—ä¸²æ‹¼æ¥æ›´å°ˆæ¥­å’Œçµæ§‹åŒ–\n",
    "   - æ”¯æ´å¤šæ¨¡æ…‹æ“´å±•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
